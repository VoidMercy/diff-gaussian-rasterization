//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32688072
// Cuda compilation tools, release 12.1, V12.1.105
// Based on NVVM 7.0.1
//

.version 8.1
.target sm_52
.address_size 64

	// .globl	_ZNSt16initializer_listIjEC1EPKjm
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.const .align 8 .b8 params[64];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust6system6detail10sequential3seqE[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust6system3cpp3parE[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust8cuda_cub3parE[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust8cuda_cub10par_nosyncE[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders2_1E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders2_2E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders2_3E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders2_4E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders2_5E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders2_6E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders2_7E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders2_8E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders2_9E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust12placeholders3_10E[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust3seqE[1];
.global .align 1 .b8 _ZN38_INTERNAL_5fa5120a_8_optix_cu_debcdc516thrust6deviceE[1];
.global .align 1 .b8 $str[23] = {67, 108, 111, 115, 101, 115, 116, 32, 40, 48, 44, 32, 48, 41, 58, 32, 37, 100, 32, 37, 102, 10, 0};

.visible .func _ZNSt16initializer_listIjEC1EPKjm(
	.param .b64 _ZNSt16initializer_listIjEC1EPKjm_param_0,
	.param .b64 _ZNSt16initializer_listIjEC1EPKjm_param_1,
	.param .b64 _ZNSt16initializer_listIjEC1EPKjm_param_2
)
{
	.reg .b64 	%rd<4>;


	ld.param.u64 	%rd1, [_ZNSt16initializer_listIjEC1EPKjm_param_0];
	ld.param.u64 	%rd2, [_ZNSt16initializer_listIjEC1EPKjm_param_1];
	ld.param.u64 	%rd3, [_ZNSt16initializer_listIjEC1EPKjm_param_2];
	st.u64 	[%rd1], %rd2;
	st.u64 	[%rd1+8], %rd3;
	ret;

}
	// .globl	__direct_callable__dc
.visible .func __direct_callable__dc(
	.param .b32 __direct_callable__dc_param_0,
	.param .b64 __direct_callable__dc_param_1,
	.param .b64 __direct_callable__dc_param_2
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<18>;


	ld.param.u32 	%r10, [__direct_callable__dc_param_0];
	ld.param.u64 	%rd11, [__direct_callable__dc_param_1];
	ld.param.u64 	%rd12, [__direct_callable__dc_param_2];
	setp.lt.s32 	%p1, %r10, 1;
	@%p1 bra 	$L__BB1_7;

	add.s32 	%r12, %r10, -1;
	and.b32  	%r22, %r10, 3;
	setp.lt.u32 	%p2, %r12, 3;
	mov.u32 	%r21, 0;
	@%p2 bra 	$L__BB1_4;

	sub.s32 	%r20, %r10, %r22;
	mov.u64 	%rd14, %rd11;
	mov.u64 	%rd15, %rd12;

$L__BB1_3:
	ld.u32 	%r14, [%rd15];
	st.u32 	[%rd14], %r14;
	ld.u32 	%r15, [%rd15+4];
	st.u32 	[%rd14+4], %r15;
	ld.u32 	%r16, [%rd15+8];
	st.u32 	[%rd14+8], %r16;
	ld.u32 	%r17, [%rd15+12];
	st.u32 	[%rd14+12], %r17;
	add.s32 	%r21, %r21, 4;
	add.s64 	%rd15, %rd15, 16;
	add.s64 	%rd14, %rd14, 16;
	add.s32 	%r20, %r20, -4;
	setp.ne.s32 	%p3, %r20, 0;
	@%p3 bra 	$L__BB1_3;

$L__BB1_4:
	setp.eq.s32 	%p4, %r22, 0;
	@%p4 bra 	$L__BB1_7;

	mul.wide.s32 	%rd13, %r21, 4;
	add.s64 	%rd17, %rd11, %rd13;
	add.s64 	%rd16, %rd12, %rd13;

$L__BB1_6:
	.pragma "nounroll";
	ld.u32 	%r18, [%rd16];
	st.u32 	[%rd17], %r18;
	add.s64 	%rd17, %rd17, 4;
	add.s64 	%rd16, %rd16, 4;
	add.s32 	%r22, %r22, -1;
	setp.ne.s32 	%p5, %r22, 0;
	@%p5 bra 	$L__BB1_6;

$L__BB1_7:
	ret;

}
	// .globl	__raygen__rg
.visible .entry __raygen__rg()
{
	.local .align 16 .b8 	__local_depot2[4112];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<7>;
	.reg .f32 	%f<59>;
	.reg .b32 	%r<142>;
	.reg .b64 	%rd<36>;


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd10, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd11, %SP, 16;
	add.u64 	%rd2, %SPL, 16;
	// begin inline asm
	call (%r31), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r32), _optix_get_launch_index_y, ();
	// end inline asm
	ld.const.v2.f32 	{%f10, %f11}, [params+24];
	mov.u32 	%r107, 0;
	add.ftz.f32 	%f14, %f10, %f10;
	cvt.rn.f32.s32 	%f15, %r31;
	add.ftz.f32 	%f16, %f15, 0f3F000000;
	ld.const.v2.u32 	{%r108, %r109}, [params+16];
	cvt.rn.f32.u32 	%f17, %r108;
	div.approx.ftz.f32 	%f18, %f16, %f17;
	mul.ftz.f32 	%f19, %f14, %f18;
	sub.ftz.f32 	%f20, %f19, %f10;
	add.ftz.f32 	%f21, %f11, %f11;
	cvt.rn.f32.s32 	%f22, %r32;
	add.ftz.f32 	%f23, %f22, 0f3F000000;
	cvt.rn.f32.u32 	%f24, %r109;
	div.approx.ftz.f32 	%f25, %f23, %f24;
	mul.ftz.f32 	%f26, %f21, %f25;
	sub.ftz.f32 	%f27, %f26, %f11;
	ld.const.u64 	%rd12, [params+32];
	cvta.to.global.u64 	%rd13, %rd12;
	ld.global.f32 	%f28, [%rd13];
	ld.global.f32 	%f29, [%rd13+16];
	mul.ftz.f32 	%f30, %f27, %f29;
	fma.rn.ftz.f32 	%f31, %f20, %f28, %f30;
	ld.global.f32 	%f32, [%rd13+32];
	add.ftz.f32 	%f33, %f31, %f32;
	ld.global.f32 	%f34, [%rd13+48];
	add.ftz.f32 	%f35, %f33, %f34;
	ld.global.f32 	%f36, [%rd13+4];
	ld.global.f32 	%f37, [%rd13+20];
	mul.ftz.f32 	%f38, %f27, %f37;
	fma.rn.ftz.f32 	%f39, %f20, %f36, %f38;
	ld.global.f32 	%f40, [%rd13+36];
	add.ftz.f32 	%f41, %f40, %f39;
	ld.global.f32 	%f42, [%rd13+52];
	add.ftz.f32 	%f43, %f41, %f42;
	ld.global.f32 	%f44, [%rd13+8];
	ld.global.f32 	%f45, [%rd13+24];
	mul.ftz.f32 	%f46, %f27, %f45;
	fma.rn.ftz.f32 	%f47, %f20, %f44, %f46;
	ld.global.f32 	%f48, [%rd13+40];
	add.ftz.f32 	%f49, %f48, %f47;
	ld.global.f32 	%f50, [%rd13+56];
	add.ftz.f32 	%f51, %f49, %f50;
	ld.const.u64 	%rd14, [params+40];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.global.f32 	%f1, [%rd15];
	sub.ftz.f32 	%f52, %f35, %f1;
	ld.global.f32 	%f2, [%rd15+4];
	sub.ftz.f32 	%f53, %f43, %f2;
	ld.global.f32 	%f3, [%rd15+8];
	sub.ftz.f32 	%f54, %f51, %f3;
	mul.ftz.f32 	%f55, %f53, %f53;
	fma.rn.ftz.f32 	%f56, %f52, %f52, %f55;
	fma.rn.ftz.f32 	%f57, %f54, %f54, %f56;
	sqrt.approx.ftz.f32 	%f58, %f57;
	div.approx.ftz.f32 	%f4, %f52, %f58;
	div.approx.ftz.f32 	%f5, %f53, %f58;
	div.approx.ftz.f32 	%f6, %f54, %f58;
	st.local.u32 	[%rd1], %r107;
	cvt.u32.u64 	%r78, %rd10;
	shr.u64 	%rd16, %rd10, 32;
	cvt.u32.u64 	%r79, %rd16;
	cvt.u32.u64 	%r80, %rd11;
	shr.u64 	%rd17, %rd11, 32;
	cvt.u32.u64 	%r81, %rd17;
	ld.const.u64 	%rd9, [params+56];
	mov.f32 	%f8, 0f5A0E1BCA;
	mov.f32 	%f9, 0f00000000;
	mov.u32 	%r70, 255;
	mov.u32 	%r71, 2;
	mov.u32 	%r75, 6;
	// begin inline asm
	call(%r37,%r38,%r39,%r40,%r41,%r42,%r43,%r44,%r45,%r46,%r47,%r48,%r49,%r50,%r51,%r52,%r53,%r54,%r55,%r56,%r57,%r58,%r59,%r60,%r61,%r62,%r63,%r64,%r65,%r66,%r67,%r68),_optix_trace_typed_32,(%r107,%rd9,%f1,%f2,%f3,%f4,%f5,%f6,%f9,%f8,%f9,%r70,%r71,%r107,%r107,%r107,%r75,%r31,%r32,%r78,%r79,%r80,%r81,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107,%r107);
	// end inline asm
	ld.local.u32 	%r5, [%rd1];
	setp.lt.s32 	%p1, %r5, 1025;
	mov.u32 	%r133, %r5;
	@%p1 bra 	$L__BB2_2;

	mov.u32 	%r133, 1024;
	st.local.u32 	[%rd1], %r133;

$L__BB2_2:
	mad.lo.s32 	%r134, %r108, %r32, %r31;
	ld.const.u64 	%rd18, [params+8];
	cvta.to.global.u64 	%rd19, %rd18;
	mul.wide.s32 	%rd20, %r134, 4;
	add.s64 	%rd21, %rd19, %rd20;
	st.global.u32 	[%rd21], %r133;
	setp.lt.s32 	%p2, %r133, 1;
	@%p2 bra 	$L__BB2_9;

	ld.const.u64 	%rd22, [params];
	cvta.to.global.u64 	%rd3, %rd22;
	and.b32  	%r141, %r133, 3;
	add.s32 	%r112, %r133, -1;
	setp.lt.u32 	%p3, %r112, 3;
	mov.u32 	%r139, 0;
	@%p3 bra 	$L__BB2_6;

	add.s32 	%r114, %r109, %r32;
	mad.lo.s32 	%r137, %r108, %r114, %r31;
	mul.lo.s32 	%r115, %r108, %r109;
	shl.b32 	%r10, %r115, 2;
	shl.b32 	%r116, %r109, 1;
	add.s32 	%r117, %r32, %r116;
	mad.lo.s32 	%r136, %r108, %r117, %r31;
	mad.lo.s32 	%r118, %r109, 3, %r32;
	mad.lo.s32 	%r135, %r108, %r118, %r31;
	not.b32 	%r119, %r5;
	max.s32 	%r120, %r119, -1025;
	add.s32 	%r121, %r120, %r141;
	add.s32 	%r13, %r121, 1;
	mov.u64 	%rd34, %rd2;

$L__BB2_5:
	ld.local.v4.u32 	{%r122, %r123, %r124, %r125}, [%rd34];
	mul.wide.u32 	%rd23, %r134, 4;
	add.s64 	%rd24, %rd3, %rd23;
	st.global.u32 	[%rd24], %r122;
	mul.wide.u32 	%rd25, %r137, 4;
	add.s64 	%rd26, %rd3, %rd25;
	st.global.u32 	[%rd26], %r123;
	mul.wide.u32 	%rd27, %r136, 4;
	add.s64 	%rd28, %rd3, %rd27;
	st.global.u32 	[%rd28], %r124;
	mul.wide.u32 	%rd29, %r135, 4;
	add.s64 	%rd30, %rd3, %rd29;
	st.global.u32 	[%rd30], %r125;
	add.s64 	%rd34, %rd34, 16;
	add.s32 	%r137, %r137, %r10;
	add.s32 	%r136, %r136, %r10;
	add.s32 	%r135, %r135, %r10;
	add.s32 	%r134, %r134, %r10;
	add.s32 	%r139, %r139, 4;
	add.s32 	%r130, %r13, %r139;
	setp.ne.s32 	%p4, %r130, 0;
	@%p4 bra 	$L__BB2_5;

$L__BB2_6:
	setp.eq.s32 	%p5, %r141, 0;
	@%p5 bra 	$L__BB2_9;

	mad.lo.s32 	%r131, %r109, %r139, %r32;
	mad.lo.s32 	%r140, %r108, %r131, %r31;
	mul.lo.s32 	%r26, %r108, %r109;
	mul.wide.s32 	%rd31, %r139, 4;
	add.s64 	%rd35, %rd2, %rd31;

$L__BB2_8:
	.pragma "nounroll";
	ld.local.u32 	%r132, [%rd35];
	mul.wide.u32 	%rd32, %r140, 4;
	add.s64 	%rd33, %rd3, %rd32;
	st.global.u32 	[%rd33], %r132;
	add.s32 	%r140, %r140, %r26;
	add.s64 	%rd35, %rd35, 4;
	add.s32 	%r141, %r141, -1;
	setp.ne.s32 	%p6, %r141, 0;
	@%p6 bra 	$L__BB2_8;

$L__BB2_9:
	ret;

}
	// .globl	_ZSt4sqrtf
.visible .func  (.param .b32 func_retval0) _ZSt4sqrtf(
	.param .b32 _ZSt4sqrtf_param_0
)
{
	.reg .f32 	%f<3>;


	ld.param.f32 	%f1, [_ZSt4sqrtf_param_0];
	sqrt.approx.ftz.f32 	%f2, %f1;
	st.param.f32 	[func_retval0+0], %f2;
	ret;

}
	// .globl	__anyhit__ah
.visible .entry __anyhit__ah()
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<9>;


	mov.u32 	%r4, 0;
	// begin inline asm
	call (%r3), _optix_get_payload, (%r4);
	// end inline asm
	mov.u32 	%r6, 1;
	// begin inline asm
	call (%r5), _optix_get_payload, (%r6);
	// end inline asm
	mov.u32 	%r8, 2;
	// begin inline asm
	call (%r7), _optix_get_payload, (%r8);
	// end inline asm
	cvt.u64.u32 	%rd2, %r7;
	mov.u32 	%r10, 3;
	// begin inline asm
	call (%r9), _optix_get_payload, (%r10);
	// end inline asm
	cvt.u64.u32 	%rd3, %r9;
	bfi.b64 	%rd4, %rd3, %rd2, 32, 32;
	mov.u32 	%r12, 4;
	// begin inline asm
	call (%r11), _optix_get_payload, (%r12);
	// end inline asm
	cvt.u64.u32 	%rd5, %r11;
	mov.u32 	%r14, 5;
	// begin inline asm
	call (%r13), _optix_get_payload, (%r14);
	// end inline asm
	cvt.u64.u32 	%rd6, %r13;
	bfi.b64 	%rd1, %rd6, %rd5, 32, 32;
	// begin inline asm
	call (%r15), _optix_read_primitive_idx, ();
	// end inline asm
	atom.add.u32 	%r2, [%rd4], 1;
	setp.lt.s32 	%p1, %r2, 1024;
	@%p1 bra 	$L__BB4_2;
	bra.uni 	$L__BB4_1;

$L__BB4_2:
	mul.wide.s32 	%rd7, %r2, 4;
	add.s64 	%rd8, %rd1, %rd7;
	st.u32 	[%rd8], %r15;
	// begin inline asm
	call _optix_ignore_intersection, ();
	// end inline asm
	bra.uni 	$L__BB4_3;

$L__BB4_1:
	// begin inline asm
	call _optix_terminate_ray, ();
	// end inline asm

$L__BB4_3:
	ret;

}
	// .globl	__closesthit__ch
.visible .entry __closesthit__ch()
{
	.local .align 16 .b8 	__local_depot5[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<17>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<5>;


	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	mov.u32 	%r3, 0;
	// begin inline asm
	call (%r2), _optix_get_payload, (%r3);
	// end inline asm
	mov.u32 	%r5, 1;
	// begin inline asm
	call (%r4), _optix_get_payload, (%r5);
	// end inline asm
	mov.u32 	%r7, 2;
	// begin inline asm
	call (%r6), _optix_get_payload, (%r7);
	// end inline asm
	mov.u32 	%r9, 3;
	// begin inline asm
	call (%r8), _optix_get_payload, (%r9);
	// end inline asm
	// begin inline asm
	call (%r10), _optix_read_primitive_idx, ();
	// end inline asm
	// begin inline asm
	call (%f2), _optix_get_ray_tmax, ();
	// end inline asm
	or.b32  	%r11, %r4, %r2;
	setp.ne.s32 	%p1, %r11, 0;
	@%p1 bra 	$L__BB5_2;

	add.u64 	%rd1, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	st.local.u32 	[%rd2], %r10;
	cvt.ftz.f64.f32 	%fd1, %f2;
	st.local.f64 	[%rd2+8], %fd1;
	mov.u64 	%rd3, $str;
	cvta.global.u64 	%rd4, %rd3;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r12, [retval0+0];
	} // callseq 0

$L__BB5_2:
	mov.b32 	%r14, %f2;
	mov.u32 	%r13, 4;
	// begin inline asm
	call _optix_set_payload, (%r13, %r14);
	// end inline asm
	mov.u32 	%r15, 5;
	// begin inline asm
	call _optix_set_payload, (%r15, %r10);
	// end inline asm
	ret;

}
	// .globl	__intersection__is
.visible .entry __intersection__is()
{
	.reg .f32 	%f<3>;
	.reg .b32 	%r<3>;


	// begin inline asm
	call (%f1), _optix_get_ray_tmax, ();
	// end inline asm
	mov.u32 	%r2, 0;
	// begin inline asm
	call (%r1), _optix_report_intersection_0, (%f1, %r2);
	// end inline asm
	ret;

}
	// .globl	__miss__ms
.visible .entry __miss__ms()
{
	.reg .b32 	%r<3>;


	mov.u32 	%r1, 5;
	mov.u32 	%r2, -1;
	// begin inline asm
	call _optix_set_payload, (%r1, %r2);
	// end inline asm
	ret;

}
	// .globl	_ZN3cub11EmptyKernelIvEEvv
.visible .entry _ZN3cub11EmptyKernelIvEEvv()
{



	ret;

}
	// .globl	_ZNSt16initializer_listIjEC2EPKjm
.visible .func _ZNSt16initializer_listIjEC2EPKjm(
	.param .b64 _ZNSt16initializer_listIjEC2EPKjm_param_0,
	.param .b64 _ZNSt16initializer_listIjEC2EPKjm_param_1,
	.param .b64 _ZNSt16initializer_listIjEC2EPKjm_param_2
)
{
	.reg .b64 	%rd<4>;


	ld.param.u64 	%rd1, [_ZNSt16initializer_listIjEC2EPKjm_param_0];
	ld.param.u64 	%rd2, [_ZNSt16initializer_listIjEC2EPKjm_param_1];
	ld.param.u64 	%rd3, [_ZNSt16initializer_listIjEC2EPKjm_param_2];
	st.u64 	[%rd1], %rd2;
	st.u64 	[%rd1+8], %rd3;
	ret;

}

